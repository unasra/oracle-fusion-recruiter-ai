{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5e7e1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader , PyPDFDirectoryLoader , TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.document import Document\n",
    "from get_embedding_function import get_embedding_function\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "DATA_PATH = \"data\"\n",
    "DATA_PATH_Md = \"data/resources/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc47113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "\n",
    "def get_embedding_function():\n",
    "    #os.environ['OPENAI_API_KEY'] = \n",
    "    embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    #azure_deployment=\"${}\",\n",
    "    openai_api_version=\"2025-01-01-preview\",  # or whatever version your deployment uses\n",
    ")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "424164ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--reset]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/Users/unasra/Library/Jupyter/runtime/kernel-v3ea979829268b375332ba3a926181f75d487cea2e.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unasra/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    # Check if the database should be cleared (using the --clear flag).\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--reset\", action=\"store_true\", help=\"Reset the database.\")\n",
    "    args = parser.parse_args()\n",
    "    if args.reset:\n",
    "        print(\"âœ¨ Clearing Database\")\n",
    "        clear_database()\n",
    "\n",
    "    # Create (or update) the data store.\n",
    "    documents = load_documents()\n",
    "    chunks = split_documents(documents)\n",
    "    print(f\"Number of documents: {len(chunks)}\")\n",
    "    add_to_chroma(chunks)\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "    document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "    # Iterate over md files in DATA_PATH_Md path and run UnstructuredMarkdownLoader on each file\n",
    "    documents = []\n",
    "    for i in os.listdir(DATA_PATH_Md):\n",
    "        print(i)\n",
    "        if i.endswith(\".md\"):\n",
    "            document_loader_md = UnstructuredMarkdownLoader(os.path.join(DATA_PATH_Md, i))\n",
    "            documents += document_loader_md.load()\n",
    "        if i.endswith(\".go\"):\n",
    "            document_loader_txt = TextLoader(os.path.join(DATA_PATH, i))\n",
    "            documents += document_loader_txt.load()\n",
    "    #document_loader_md = TextDirectoryLoader(DATA_PATH_Md)\n",
    "    documents_all = document_loader.load() + document_loader_md.load()\n",
    "    return documents_all\n",
    "\n",
    "\n",
    "def split_documents(documents: list[Document]):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,\n",
    "        chunk_overlap=80,\n",
    "        length_function=len,\n",
    "        is_separator_regex=False,\n",
    "    )\n",
    "    return text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "def add_to_chroma(chunks: list[Document]):\n",
    "    # Load the existing database.\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
    "    )\n",
    "\n",
    "    # Calculate Page IDs.\n",
    "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
    "\n",
    "    # Add or Update the documents.\n",
    "    existing_items = db.get(include=[])  # IDs are always included by default\n",
    "    existing_ids = set(existing_items[\"ids\"])\n",
    "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
    "\n",
    "    # Only add documents that don't exist in the DB.\n",
    "    new_chunks = []\n",
    "    for chunk in chunks_with_ids:\n",
    "        if chunk.metadata[\"id\"] not in existing_ids:\n",
    "            new_chunks.append(chunk)\n",
    "\n",
    "    if len(new_chunks):\n",
    "        print(f\"ðŸ‘‰ Adding new documents: {len(new_chunks)}\")\n",
    "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
    "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
    "        db.persist()\n",
    "    else:\n",
    "        print(\"âœ… No new documents to add\")\n",
    "\n",
    "\n",
    "def calculate_chunk_ids(chunks):\n",
    "\n",
    "    # This will create IDs like \"data/monopoly.pdf:6:2\"\n",
    "    # Page Source : Page Number : Chunk Index\n",
    "\n",
    "    last_page_id = None\n",
    "    current_chunk_index = 0\n",
    "\n",
    "    for chunk in chunks:\n",
    "        source = chunk.metadata.get(\"source\")\n",
    "        page = chunk.metadata.get(\"page\")\n",
    "        current_page_id = f\"{source}:{page}\"\n",
    "\n",
    "        # If the page ID is the same as the last one, increment the index.\n",
    "        if current_page_id == last_page_id:\n",
    "            current_chunk_index += 1\n",
    "        else:\n",
    "            current_chunk_index = 0\n",
    "\n",
    "        # Calculate the chunk ID.\n",
    "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
    "        last_page_id = current_page_id\n",
    "\n",
    "        # Add it to the page meta-data.\n",
    "        chunk.metadata[\"id\"] = chunk_id\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def clear_database():\n",
    "    if os.path.exists(CHROMA_PATH):\n",
    "        shutil.rmtree(CHROMA_PATH)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f9f2416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script: Extract Pydantic BaseModel Schemas and Use them with LLM Structured Output\n",
    "\n",
    "def load_tf_script(context: str,user_prompt: str):\n",
    "\n",
    "    import os\n",
    "    import importlib.util\n",
    "    import inspect\n",
    "    import importlib\n",
    "    import sys\n",
    "    import dns_config\n",
    "    from pathlib import Path\n",
    "    from typing import  Type , Any, ClassVar, Dict, List, Optional\n",
    "    from pydantic import BaseModel , StrictBool, StrictInt, StrictStr\n",
    "    from datetime import datetime\n",
    "    from langchain.llms import OpenAI\n",
    "    from langchain.output_parsers import PydanticOutputParser\n",
    "    from langchain_openai import AzureChatOpenAI\n",
    "    from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "    model_registry: dict[str, Type[BaseModel]] = {}\n",
    "    loaded_modules = {}\n",
    "\n",
    "    SCHEMAS_PACKAGE = \"dns_config\"  # Should contain __init__.py importing all models\n",
    "\n",
    "    model_registry: Dict[str, Type[BaseModel]] = {}\n",
    "\n",
    "    try:\n",
    "        schemas_module = importlib.import_module(SCHEMAS_PACKAGE)\n",
    "    except Exception as e:\n",
    "        raise ImportError(f\"Could not import {SCHEMAS_PACKAGE}: {e}\")\n",
    "\n",
    "    # Extract BaseModels and rebuild them\n",
    "    for name, obj in inspect.getmembers(schemas_module):\n",
    "        if inspect.isclass(obj) and issubclass(obj, BaseModel):\n",
    "            try:\n",
    "                obj.model_rebuild(force=True)  # Rebuild to resolve forward refs\n",
    "                model_registry[name.lower()] = obj  # store by lowercase name for keyword matching\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to rebuild model {name}: {e}\")\n",
    "\n",
    "    # 2. Accept user input and select appropriate schema\n",
    "    #user_prompt = \"Create a Server\"\n",
    "\n",
    "    matched_models = []\n",
    "    for keyword, model_class in model_registry.items():\n",
    "        if keyword in user_prompt.lower():\n",
    "            matched_models.append((keyword, model_class))\n",
    "\n",
    "    if not matched_models:\n",
    "        raise ValueError(\"No matching schema found for user input.\")\n",
    "\n",
    "\n",
    "    # 3. Use with LangChain structured output\n",
    "    llm = AzureChatOpenAI(model_name=\"gpt-4.1\", temperature=0,api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),api_version=\"2025-01-01-preview\")\n",
    "    combined_outputs = {}\n",
    "\n",
    "    # 3. Generate structured outputs for each matched model\n",
    "    for keyword, matched_model in matched_models:\n",
    "        print(f\"\\nUsing schema: {matched_model.__name__}\")\n",
    "        #print(matched_model.model_json_schema())\n",
    "        #matched_model.model_rebuild()\n",
    "        parser = PydanticOutputParser(pydantic_object=matched_model)\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        Generate a valid terraform HCL matching this requirements:\n",
    "        You are an expert at converting sanitzing Terraform HCL Code\n",
    "        You are given a schema and an unsanitized HCL code block. Your task is to generate a sanitized HCL code block that matches the schema.\n",
    "\n",
    "        {parser.get_format_instructions()}\n",
    "\n",
    "        Unsanitized Code Block : {context}\n",
    "        \n",
    "        \"\"\"\n",
    "        prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "        prompt2 = prompt_template.format(context=context)\n",
    "        # Only generate the output relevant to: {keyword}\n",
    "        #prompt_template = ChatPromptTemplate.from_template(prompt)\n",
    "        response = llm.invoke(prompt2)\n",
    "        #print(f\"Response: {response.pretty_print()}\")\n",
    "        #parsed_output = parser.parse(response.content)\n",
    "        return response.content\n",
    "\n",
    "    # 4. Print combined output\n",
    "    print(\"\\nCombined Output:\")\n",
    "    print(combined_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66ad57d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using schema: View\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'\"properties\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 64\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response_text\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 34\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Create CLI.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# parser = argparse.ArgumentParser()\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# parser.add_argument(\"query_text\", type=str, help=\"The query text.\")\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# args = parser.parse_args()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# query_text = args.query_text\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     query_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate a DNS View\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m     \u001b[43mquery_rag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[86], line 58\u001b[0m, in \u001b[0;36mquery_rag\u001b[0;34m(query_text)\u001b[0m\n\u001b[1;32m     55\u001b[0m formatted_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#print(formatted_response)\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mload_tf_script\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_text\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43mquery_text\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_text\n",
      "Cell \u001b[0;32mIn[84], line 77\u001b[0m, in \u001b[0;36mload_tf_script\u001b[0;34m(context, user_prompt)\u001b[0m\n\u001b[1;32m     66\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124mGenerate a valid terraform HCL matching this requirements:\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124mYou are an expert at converting sanitzing Terraform HCL Code\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124m\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     76\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_template(prompt)\n\u001b[0;32m---> 77\u001b[0m prompt2 \u001b[38;5;241m=\u001b[39m \u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Only generate the output relevant to: {keyword}\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m#prompt_template = ChatPromptTemplate.from_template(prompt)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m response \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(prompt2)\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/prompts/chat.py:702\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    693\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format the chat template into a string.\u001b[39;00m\n\u001b[1;32m    694\u001b[0m \n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;124;03m        formatted string.\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 702\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_string()\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/prompts/chat.py:725\u001b[0m, in \u001b[0;36mBaseChatPromptTemplate.format_prompt\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_prompt\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PromptValue:\n\u001b[1;32m    717\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt. Should return a PromptValue.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;124;03m        PromptValue.\u001b[39;00m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 725\u001b[0m     messages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatPromptValue(messages\u001b[38;5;241m=\u001b[39mmessages)\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/prompts/chat.py:1186\u001b[0m, in \u001b[0;36mChatPromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1182\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend([message_template])\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1184\u001b[0m     message_template, (BaseMessagePromptTemplate, BaseChatPromptTemplate)\n\u001b[1;32m   1185\u001b[0m ):\n\u001b[0;32m-> 1186\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[43mmessage_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1187\u001b[0m     result\u001b[38;5;241m.\u001b[39mextend(message)\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/prompts/chat.py:558\u001b[0m, in \u001b[0;36m_StringImageMessagePromptTemplate.format_messages\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat_messages\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[BaseMessage]:\n\u001b[1;32m    550\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format messages from kwargs.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \n\u001b[1;32m    552\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m        List of BaseMessages.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/prompts/chat.py:591\u001b[0m, in \u001b[0;36m_StringImageMessagePromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt template.\u001b[39;00m\n\u001b[1;32m    583\u001b[0m \n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;124;03m    Formatted message.\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt, StringPromptTemplate):\n\u001b[0;32m--> 591\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_msg_class(\n\u001b[1;32m    593\u001b[0m         content\u001b[38;5;241m=\u001b[39mtext, additional_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madditional_kwargs\n\u001b[1;32m    594\u001b[0m     )\n\u001b[1;32m    595\u001b[0m content: \u001b[38;5;28mlist\u001b[39m \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/prompts/prompt.py:186\u001b[0m, in \u001b[0;36mPromptTemplate.format\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \n\u001b[1;32m    179\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    A formatted string.\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    185\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_partial_and_user_variables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDEFAULT_FORMATTER_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate_format\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtemplate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/string.py:161\u001b[0m, in \u001b[0;36mFormatter.format\u001b[0;34m(self, format_string, *args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/rag-tutorial-v2/.venv/lib/python3.9/site-packages/langchain_core/utils/formatting.py:33\u001b[0m, in \u001b[0;36mStrictFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo arguments should be provided, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meverything should be passed as keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     )\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/string.py:165\u001b[0m, in \u001b[0;36mFormatter.vformat\u001b[0;34m(self, format_string, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_string, args, kwargs):\n\u001b[1;32m    164\u001b[0m     used_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m--> 165\u001b[0m     result, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformat_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mused_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_unused_args(used_args, args, kwargs)\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/string.py:205\u001b[0m, in \u001b[0;36mFormatter._vformat\u001b[0;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001b[0m\n\u001b[1;32m    201\u001b[0m     auto_arg_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# given the field_name, find the object it references\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m#  and the argument it came from\u001b[39;00m\n\u001b[0;32m--> 205\u001b[0m obj, arg_used \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m used_args\u001b[38;5;241m.\u001b[39madd(arg_used)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# do any conversion on the resulting object\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/string.py:270\u001b[0m, in \u001b[0;36mFormatter.get_field\u001b[0;34m(self, field_name, args, kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_field\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, args, kwargs):\n\u001b[1;32m    268\u001b[0m     first, rest \u001b[38;5;241m=\u001b[39m _string\u001b[38;5;241m.\u001b[39mformatter_field_name_split(field_name)\n\u001b[0;32m--> 270\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# loop through the rest of the field_name, doing\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;66;03m#  getattr or getitem as needed\u001b[39;00m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m is_attr, i \u001b[38;5;129;01min\u001b[39;00m rest:\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/string.py:227\u001b[0m, in \u001b[0;36mFormatter.get_value\u001b[0;34m(self, key, args, kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args[key]\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: '\"properties\"'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_community.llms.ollama import Ollama\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from get_embedding_function import get_embedding_function\n",
    "\n",
    "CHROMA_PATH = \"chroma\"\n",
    "\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Create CLI.\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument(\"query_text\", type=str, help=\"The query text.\")\n",
    "    # args = parser.parse_args()\n",
    "    # query_text = args.query_text\n",
    "    query_text = \"Create a DNS View\"\n",
    "    query_rag(query_text)\n",
    "\n",
    "\n",
    "def query_rag(query_text: str):\n",
    "    # Prepare the DB.\n",
    "    embedding_function = get_embedding_function()\n",
    "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "\n",
    "    # Search the DB.\n",
    "    results = db.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "    # print(prompt)\n",
    "\n",
    "\n",
    "    model = AzureChatOpenAI(model_name=\"gpt-4.1\", temperature=0,api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),api_version=\"2025-01-01-preview\")\n",
    "    response_text = model.invoke(prompt)\n",
    "\n",
    "    #sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
    "    formatted_response = f\"Response: {response_text}\"\n",
    "    #print(formatted_response)\n",
    "\n",
    "    print(load_tf_script(response_text.content,query_text))\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11370502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
